{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal, fft\n",
    "from scipy.linalg import toeplitz, solve\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython\n",
    "os.environ['NUMBA_CACHE_DIR'] = IPython.paths.get_ipython_cache_dir()\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpc_analysis(s, p=20):\n",
    "    \"\"\" compute the LPC analysis using the autocorrelation method\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy array\n",
    "        windowed signal frame as a numpy 1D array.\n",
    "    p : int\n",
    "        model order.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ak : numpy array\n",
    "         model coefficients.\n",
    "    e : float\n",
    "        minimum mean squared error.\n",
    "    e_norm : float\n",
    "             normalized minimum mean squared error.\n",
    "    \"\"\"\n",
    "    # frame length\n",
    "    N = s.shape[0]\n",
    "    \n",
    "    # compute autocorrelation values\n",
    "    r = np.zeros((p+1, 1))\n",
    "    for k in range(p+1):\n",
    "        r[k] = np.dot(s[:N-k].T, s[k:])\n",
    "\n",
    "    # solve to compute model coefficients\n",
    "    ak = solve(toeplitz(r[:p]), r[1:]).squeeze()\n",
    "\n",
    "    # compute mean squared error\n",
    "    e = r[0] - np.dot(ak.T, r[1:])\n",
    "\n",
    "    # compute normalized mean squared error\n",
    "    e_norm = e / r[0]\n",
    "\n",
    "    return ak, e, e_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formantes(file, fs=22050, N=460, p=20, umbral1=120, umbral2=250):\n",
    "    \n",
    "    if np.max(abs(file))>1e-8:\n",
    "        x = file / np.max(abs(file)) * 0.9  #normalización\n",
    "    else:\n",
    "        return -1, -1\n",
    "    \n",
    "    #Enventanado\n",
    "    # sample del medio de la señal\n",
    "    ind_mid = int(len(x)/2)\n",
    "    # signal frame\n",
    "    s = x[ind_mid-int(N/2):ind_mid+int(N/2)]\n",
    "    # smoothing window\n",
    "    window = signal.windows.get_window('hann', N)\n",
    "    # windowed signal frame\n",
    "    s_win = s * window\n",
    "\n",
    "    ak, _, _ = lpc_analysis(s_win, p)  #LPC\n",
    "\n",
    "    #Formantes\n",
    "    # raíces del filtro\n",
    "    raices = np.roots(np.concatenate(([1], -ak)))\n",
    "    # nos quedamos con polos complejos con ángulo menor a pi\n",
    "    polos = raices[raices.imag>0]\n",
    "    # descomponemos en ganancia y ángulo\n",
    "    Ak = np.abs(polos)\n",
    "    omegak = np.angle(polos)\n",
    "    # calculamos frecuencia y estimamos ancho de banda de los polos\n",
    "    fk = omegak*fs/(2*np.pi)\n",
    "    BWk = fs*np.log(1/Ak)/np.pi\n",
    "    # nos quedamos con los polos con ancho menor a umbral\n",
    "    fk_sort = np.sort(fk[BWk<=umbral1], axis=0)\n",
    "    if len(fk_sort)<2:\n",
    "        fk_sort = np.sort(fk[BWk<=umbral2], axis=0)\n",
    "\n",
    "    return fk_sort[0], fk_sort[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancias_vocales(F1, F2):\n",
    "    \n",
    "    vocales = np.array(((800, 1170), (480, 2300), (240, 2800), (510, 960), (250, 630)))\n",
    "    # vocales = np.array(((240, 2400), (235, 2100), (390, 2300), (370, 1900), (610, 1900), (585, 1710), (850, 1610), (820, 1530), (750, 940), (700, 760), (600, 1170), (500, 700), (460, 1310), (360, 640), (300, 1390), (250, 595)))\n",
    "    # vocales_str = ['a', 'e', 'i', 'o', 'u']\n",
    "    distancias = np.linalg.norm(vocales-(F1,F2), ord=2, axis=1)\n",
    "    # vocal = np.argmin(distancias)\n",
    "\n",
    "    return distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ST_distancias_vocales(s, L=2048, R=256):\n",
    "    \"\"\" compute the analysis phase of the phase vocoder, i.e. the STFT of the input audio signal\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy array\n",
    "        input audio signal (mono) as a numpy 1D array.\n",
    "    L : int\n",
    "        window length in samples.\n",
    "    R : int\n",
    "        hop size in samples.\n",
    "    win : string\n",
    "          window type as defined in scipy.signal.windows.    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X_stft : numpy array\n",
    "             STFT of x as a numpy 2D array.\n",
    "    omega_stft : numpy array\n",
    "                 frequency values in radians.\n",
    "    samps_stft : numpy array\n",
    "                 time sample at the begining of each frame.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # length of the input signal\n",
    "    M = s.size;      \n",
    "    \n",
    "    # total number of analysis frames\n",
    "    num_frames = int(np.floor((M - L) / R))\n",
    "\n",
    "    # initialize stft\n",
    "    distancias = np.zeros((5, num_frames))\n",
    "    \n",
    "    # process each frame\n",
    "    for ind in range(num_frames):\n",
    "\n",
    "        # initial and ending points of the frame\n",
    "        n_ini = int(ind * R)\n",
    "        n_end = n_ini + L\n",
    "\n",
    "        # signal frame\n",
    "        s_w = s[n_ini:n_end]\n",
    "\n",
    "        # save DFT of the signal frame\n",
    "        [F1, F2] = formantes(s_w, N=200, p=9, umbral1=150, umbral2=10000)\n",
    "        if F1!=-1:\n",
    "            distancias[:, ind] = distancias_vocales(F1, F2)\n",
    "            # if np.min(distancias[:, ind])>750:\n",
    "            #     distancias[:, ind] = np.zeros(5)\n",
    "        else:\n",
    "            distancias[:, ind] = np.zeros(5)\n",
    "        \n",
    "    # frequency values in radians    \n",
    "    # quefrencys = np.arange(N)\n",
    "\n",
    "    # # time sample at the center of each frame\n",
    "    # samps_ceps = np.arange(L/2, M-L/2+1, R)[:-1]\n",
    " \n",
    "    return distancias#, samps_ceps, quefrencys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_files = './data/'\n",
    "\n",
    "X_wav, Fs = librosa.load(dir_files + 'Emily_Linge-vocals.wav')\n",
    "Y_wav, Fs = librosa.load(dir_files + 'Sting-vocals.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libtsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_chroma_shift = 2\n",
    "# pitch_shift_for_audio_1 = -opt_chroma_shift % 12\n",
    "# audio_1_shifted = libtsm.pitch_shift(X_wav, pitch_shift_for_audio_1 * 100, order=\"tsm-res\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = int(0.02*Fs)\n",
    "X = ST_distancias_vocales(X_wav, L=H, R=H)\n",
    "X = 1 - X/X.max()\n",
    "Y = ST_distancias_vocales(Y_wav, L=H, R=H)\n",
    "Y = 1 - Y/Y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = np.arange(0, len(X_wav)-2*H, H)\n",
    "ty = np.arange(0, len(Y_wav)-2*H, H)\n",
    "l = np.arange(5)\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.pcolormesh(tx, l, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.pcolormesh(ty, l, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libfmp.c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = libfmp.c3.compute_cost_matrix(X, Y)\n",
    "D = libfmp.c3.compute_accumulated_cost_matrix(C)\n",
    "P = libfmp.c3.compute_optimal_warping_path(D)\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(15, 5))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "libfmp.c3.plot_matrix_with_points(C, P, linestyle='-',  marker='', \n",
    "    ax=[ax], aspect='equal', clim=[0, np.max(C)], \n",
    "    title='$C$ with optimal warping path', xlabel='Sequence Y', ylabel='Sequence X');\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "libfmp.c3.plot_matrix_with_points(D, P, linestyle='-', marker='', \n",
    "    ax=[ax], aspect='equal', clim=[0, np.max(D)], \n",
    "    title='$D$ with optimal warping path', xlabel='Sequence Y', ylabel='Sequence X');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synctoolbox.dtw.utils import compute_optimal_chroma_shift, shift_chroma_vectors, make_path_strictly_monotonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of warping path obtained from MrMsDTW:', P.T.shape[1])\n",
    "wp = make_path_strictly_monotonic(P.T)\n",
    "print('Length of warping path made strictly monotonic:', wp.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libtsm\n",
    "\n",
    "# pitch_shift_for_audio_1 = -opt_chroma_shift % 12\n",
    "# if pitch_shift_for_audio_1 > 6:\n",
    "#     pitch_shift_for_audio_1 -= 12\n",
    "# audio_1_shifted = libtsm.pitch_shift(X_wav, pitch_shift_for_audio_1 * 100, order=\"tsm-res\")\n",
    "\n",
    "# The TSM functionality of the libtsm library expects the warping path to be given in audio samples.\n",
    "# Here, we do the conversion and additionally clip values that are too large.\n",
    "time_map = wp.T * H\n",
    "time_map = np.concatenate((time_map, np.array([[len(X_wav)-1,len(Y_wav)-1]])))\n",
    "\n",
    "time_map = libtsm.ensure_validity(time_map)\n",
    "\n",
    "y_hpstsm = libtsm.hps_tsm(X_wav, time_map)\n",
    "stereo_sonification = np.hstack((Y_wav.reshape(-1, 1), y_hpstsm))\n",
    "\n",
    "# print('Original signal 1', flush=True)\n",
    "# ipd.display(ipd.Audio(X_wav, rate=Fs, normalize=True))\n",
    "\n",
    "# print('Original signal 2', flush=True)\n",
    "# ipd.display(ipd.Audio(Y_wav, rate=Fs, normalize=True))\n",
    "\n",
    "print('Synchronized versions', flush=True)\n",
    "ipd.display(ipd.Audio(stereo_sonification.T, rate=Fs, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_envolvente(file, fs=22050, Ndft=1024, N=460, p=20):\n",
    "    \n",
    "    if np.max(abs(file))>1e-8:\n",
    "        x = file / np.max(abs(file)) * 0.9  #normalización\n",
    "    else:\n",
    "        return 0, 0\n",
    "    \n",
    "    #Enventanado\n",
    "    # sample del medio de la señal\n",
    "    ind_mid = int(len(x)/2)\n",
    "    # signal frame\n",
    "    s = x[ind_mid-int(N/2):ind_mid+int(N/2)]\n",
    "    # smoothing window\n",
    "    window = signal.windows.get_window('hann', N)\n",
    "    # windowed signal frame\n",
    "    s_win = s * window\n",
    "\n",
    "    # spectrum of the signal frame\n",
    "    X = np.fft.fft(s_win, Ndft)\n",
    "    # frequency values\n",
    "    f = np.fft.fftfreq(Ndft) * fs\n",
    "\n",
    "    # magnitude spectrum\n",
    "    magX = np.abs(X)\n",
    "    ind_fmx = int(Ndft/2)\n",
    "\n",
    "    ak, e, e_norm = lpc_analysis(s_win, p)  #LPC\n",
    "\n",
    "    # filter obtained from the lpc analysis\n",
    "    S = 1\n",
    "    U = np.concatenate([[1], -ak])\n",
    "\n",
    "    # compute gain \n",
    "    G = np.sqrt(e)\n",
    "\n",
    "    # compute the frequency response of the digital filter\n",
    "    w, H = signal.freqz(G*S, U, worN=Ndft, whole=True)\n",
    "    fw = w / (2 * np.pi) * fs\n",
    "\n",
    "    # magnitude spectrum\n",
    "    magH = np.abs(H)\n",
    "    ind_fmx = int(Ndft/2)\n",
    "\n",
    "    # plot the frequency response\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(f[:ind_fmx], 20 * np.log10(magX[:ind_fmx]), 'k', label='Respuesta en frecuencia de la señal')\n",
    "    plt.plot(f[:ind_fmx], 20 * np.log10(magH[:ind_fmx]), 'r', label='Respuesta en frecuencia del modelo todo-polos')\n",
    "    plt.ylabel('Magnitud (dB)')\n",
    "    plt.xlabel('Frecuencia (Hz)')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1060\n",
    "print(n*H/Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_envolvente(X_wav[n*H:(n+1)*H], N=200, p=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_envolvente(Y_wav[n*H:(n+1)*H], N=200, p=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sync",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
