{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import scipy.fft\n",
    "from scipy.linalg import toeplitz, solve\n",
    "\n",
    "from scipy import io, signal\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython\n",
    "os.environ['NUMBA_CACHE_DIR'] = IPython.paths.get_ipython_cache_dir()\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpc_analysis(s, p=20):\n",
    "    \"\"\" compute the LPC analysis using the autocorrelation method\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy array\n",
    "        windowed signal frame as a numpy 1D array.\n",
    "    p : int\n",
    "        model order.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ak : numpy array\n",
    "         model coefficients.\n",
    "    e : float\n",
    "        minimum mean squared error.\n",
    "    e_norm : float\n",
    "             normalized minimum mean squared error.\n",
    "    \"\"\"\n",
    "    # frame length\n",
    "    N = s.shape[0]\n",
    "    \n",
    "    # compute autocorrelation values\n",
    "    r = np.zeros((p+1, 1))\n",
    "    for k in range(p+1):\n",
    "        r[k] = np.dot(s[:N-k].T, s[k:])\n",
    "\n",
    "    # solve to compute model coefficients\n",
    "    ak = solve(toeplitz(r[:p]), r[1:]).squeeze()\n",
    "\n",
    "    # compute mean squared error\n",
    "    e = r[0] - np.dot(ak.T, r[1:])\n",
    "\n",
    "    # compute normalized mean squared error\n",
    "    e_norm = e / r[0]\n",
    "\n",
    "    return ak, e, e_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpc_decomposition(s_win, ak, e, fs, Ndft, Nw):\n",
    "    # filter obtained from the lpc analysis\n",
    "    S = 1\n",
    "    U = np.concatenate([[1], -ak])\n",
    "\n",
    "    # compute gain \n",
    "    G = np.sqrt(e)\n",
    "\n",
    "    # compute the frequency response of the digital filter\n",
    "    w, H = signal.freqz(G*S, U, worN=Ndft, whole=True)\n",
    "    fw = w / (2 * np.pi) * fs\n",
    "\n",
    "    # impulse response of the LPC filter\n",
    "    delta = np.zeros(Nw)\n",
    "    delta[0] = 1\n",
    "    h = signal.lfilter(G*S, U, delta)\n",
    "\n",
    "    # magnitude spectrum\n",
    "    magH = np.abs(H)\n",
    "    ind_fmx = int(Ndft/2)\n",
    "\n",
    "    # inverse filter\n",
    "    A = S*G\n",
    "    B = U\n",
    "\n",
    "    # compute the excitation from the inverse filter\n",
    "    p = signal.lfilter(B, A, s_win)\n",
    "\n",
    "    # compute the spectrum of the excitation\n",
    "    P = np.fft.fft(p, Ndft)\n",
    "\n",
    "    return H, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_STFT_LPC(x, fs, L=2048, R=256, win='hann'):\n",
    "    \"\"\" compute the analysis phase of the phase vocoder, i.e. the STFT of the input audio signal\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy array\n",
    "        input audio signal (mono) as a numpy 1D array.\n",
    "    L : int\n",
    "        window length in samples.\n",
    "    R : int\n",
    "        hop size in samples.\n",
    "    win : string\n",
    "          window type as defined in scipy.signal.windows.    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X_stft : numpy array\n",
    "             STFT of x as a numpy 2D array.\n",
    "    omega_stft : numpy array\n",
    "                 frequency values in radians.\n",
    "    samps_stft : numpy array\n",
    "                 time sample at the begining of each frame.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # length of the input signal\n",
    "    M = x.size;      \n",
    "    \n",
    "    # number of points to compute the DFT (FFT)\n",
    "    N = L\n",
    "    \n",
    "    # analysis window\n",
    "    window = signal.windows.get_window(win, L)\n",
    "   \n",
    "    # total number of analysis frames\n",
    "    num_frames = int(np.floor((M - L) / R))\n",
    "\n",
    "    # initialize stft\n",
    "    X_stft = np.zeros((N, num_frames), dtype = complex)\n",
    "    X_env = np.zeros((N, num_frames), dtype = complex)\n",
    "    X_exc = np.zeros((N, num_frames), dtype = complex)\n",
    "    \n",
    "    # process each frame\n",
    "    for ind in range(num_frames):\n",
    "\n",
    "        # initial and ending points of the frame\n",
    "        n_ini = int(ind * R)\n",
    "        n_end = n_ini + L\n",
    "\n",
    "        # signal frame\n",
    "        xr = window*x[n_ini:n_end]\n",
    "\n",
    "        # save DFT of the signal frame\n",
    "        X_stft[:, ind] = scipy.fft.fft(xr, N)\n",
    "\n",
    "        # LPC\n",
    "        if np.max(abs(xr))>1e-8:\n",
    "            ak, e, _ = lpc_analysis(xr, p=20)\n",
    "            X_env[:, ind], X_exc[:, ind] = lpc_decomposition(xr, ak, e, fs, N, N)\n",
    "        \n",
    "    # frequency values in radians    \n",
    "    omega_stft = 2*np.pi*np.arange(N)/N\n",
    "\n",
    "    # time sample at the center of each frame\n",
    "    samps_stft = np.arange(L/2, M-L/2, R)[:-1]\n",
    " \n",
    "    return X_stft, X_env, X_exc, omega_stft, samps_stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesis_STFT(X_stft, L=2048, R=256, win='hann'):\n",
    "    \"\"\" compute the synthesis using the IFFT of each frame combined with overlap-add\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_stft : numpy array\n",
    "             STFT of x as a numpy 2D array.\n",
    "    L : int\n",
    "        window length in samples.\n",
    "    R : int\n",
    "        hop size in samples.\n",
    "    win : string\n",
    "          window type as defined in scipy.signal.windows.    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x : numpy array\n",
    "        output audio signal (mono) as a numpy 1D array.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # number of frequency bins\n",
    "    N = X_stft.shape[0];      \n",
    " \n",
    "    # analysis window\n",
    "    window = signal.windows.get_window(win, L)\n",
    "   \n",
    "    # total number of analysis frames\n",
    "    num_frames = X_stft.shape[1]\n",
    "\n",
    "    # initialize otuput signal in the time domain\n",
    "    y = np.zeros(num_frames * R + L)\n",
    "    \n",
    "    # process each frame\n",
    "    for ind in range(num_frames):\n",
    "\n",
    "        # reconstructed signal frame\n",
    "        yr = scipy.fft.ifft(X_stft[:,ind], L).real\n",
    "\n",
    "        # initial and ending points of the frame\n",
    "        n_ini = ind*R\n",
    "        n_end = ind*R + L\n",
    "\n",
    "        # overlap-add the signal frame\n",
    "        y[n_ini:n_end] += window*yr\n",
    "        \n",
    "    # compute the amplitude scaling factor\n",
    "    C = (L/2)/R\n",
    "    \n",
    "    # compensate the amplitude scaling factor\n",
    "    y /= C\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_files = './data/'\n",
    "\n",
    "X_wav, Fs = librosa.load(dir_files + 'Emily_Linge-vocals.wav')\n",
    "Y_wav, Fs = librosa.load(dir_files + 'Police-vocals-guitar.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_offset_1 = librosa.estimate_tuning(y=X_wav, sr=Fs)\n",
    "tuning_offset_2 = librosa.estimate_tuning(y=Y_wav, sr=Fs)\n",
    "print('Estimated tuning deviation for recording 1: %f cents, for recording 2: %f cents' % (tuning_offset_1, tuning_offset_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2048\n",
    "H = 4096\n",
    "X = librosa.feature.chroma_stft(y=X_wav, sr=Fs, norm=2, hop_length=H, n_fft=N, tuning=tuning_offset_1)\n",
    "X = X / X.max()\n",
    "Y = librosa.feature.chroma_stft(y=Y_wav, sr=Fs, norm=2, hop_length=H, n_fft=N, tuning=tuning_offset_2)\n",
    "Y = Y / Y.max()\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.title('Sequence $X$')\n",
    "librosa.display.specshow(X, x_axis='frames', y_axis='chroma', cmap='gray_r', hop_length=H)\n",
    "plt.xlabel('Time (frames)')\n",
    "plt.ylabel('Chroma')\n",
    "plt.colorbar()\n",
    "plt.clim([0, 1])\n",
    "plt.tight_layout(); plt.show()\n",
    "# ipd.display(ipd.Audio(X_wav, rate=Fs))\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.title('Sequence $Y$')\n",
    "librosa.display.specshow(Y, x_axis='frames', y_axis='chroma', cmap='gray_r', hop_length=H)\n",
    "plt.xlabel('Time (frames)')\n",
    "plt.ylabel('Chroma')\n",
    "plt.colorbar()\n",
    "plt.clim([0, 1])\n",
    "plt.tight_layout(); plt.show()\n",
    "# ipd.display(ipd.Audio(Y_wav, rate=Fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synctoolbox.dtw.utils import compute_optimal_chroma_shift, shift_chroma_vectors, make_path_strictly_monotonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_chroma_shift = compute_optimal_chroma_shift(X, Y)\n",
    "print('Pitch shift between recording 1 and recording 2, determined by DTW:', opt_chroma_shift, 'bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2048\n",
    "H = int(0.02*Fs)\n",
    "X = librosa.feature.chroma_stft(y=X_wav, sr=Fs, norm=2, hop_length=H, n_fft=N, tuning=tuning_offset_1)\n",
    "X = X / X.max()\n",
    "Y = librosa.feature.chroma_stft(y=Y_wav, sr=Fs, norm=2, hop_length=H, n_fft=N, tuning=tuning_offset_2)\n",
    "Y = Y / Y.max()\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.title('Sequence $X$')\n",
    "librosa.display.specshow(X, x_axis='frames', y_axis='chroma', cmap='gray_r', hop_length=H)\n",
    "plt.xlabel('Time (frames)')\n",
    "plt.ylabel('Chroma')\n",
    "plt.colorbar()\n",
    "plt.clim([0, 1])\n",
    "plt.tight_layout(); plt.show()\n",
    "# ipd.display(ipd.Audio(X_wav, rate=Fs))\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.title('Sequence $Y$')\n",
    "librosa.display.specshow(Y, x_axis='frames', y_axis='chroma', cmap='gray_r', hop_length=H)\n",
    "plt.xlabel('Time (frames)')\n",
    "plt.ylabel('Chroma')\n",
    "plt.colorbar()\n",
    "plt.clim([0, 1])\n",
    "plt.tight_layout(); plt.show()\n",
    "# ipd.display(ipd.Audio(Y_wav, rate=Fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = shift_chroma_vectors(Y, opt_chroma_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "plt.title('Sequence $X$')\n",
    "librosa.display.specshow(X, x_axis='frames', y_axis='chroma', cmap='gray_r', hop_length=H)\n",
    "plt.xlabel('Time (frames)')\n",
    "plt.ylabel('Chroma')\n",
    "plt.colorbar()\n",
    "plt.clim([0, 1])\n",
    "plt.tight_layout(); plt.show()\n",
    "# ipd.display(ipd.Audio(X_wav, rate=Fs))\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.title('Sequence $Y$ (Shifted)')\n",
    "librosa.display.specshow(Y, x_axis='frames', y_axis='chroma', cmap='gray_r', hop_length=H)\n",
    "plt.xlabel('Time (frames)')\n",
    "plt.ylabel('Chroma')\n",
    "plt.colorbar()\n",
    "plt.clim([0, 1])\n",
    "plt.tight_layout(); plt.show()\n",
    "# ipd.display(ipd.Audio(Y_wav, rate=Fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libfmp.c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = libfmp.c3.compute_cost_matrix(X, Y)\n",
    "D = libfmp.c3.compute_accumulated_cost_matrix(C)\n",
    "P = libfmp.c3.compute_optimal_warping_path(D)\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "libfmp.c3.plot_matrix_with_points(C, P, linestyle='-',  marker='', \n",
    "    ax=[ax], aspect='equal', clim=[0, np.max(C)], \n",
    "    title='$C$ with optimal warping path', xlabel='Sequence Y', ylabel='Sequence X');\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "libfmp.c3.plot_matrix_with_points(D, P, linestyle='-', marker='', \n",
    "    ax=[ax], aspect='equal', clim=[0, np.max(D)], \n",
    "    title='$D$ with optimal warping path', xlabel='Sequence Y', ylabel='Sequence X');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[1]\n",
    "M = Y.shape[1]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "ax_X = plt.axes([0, 0.60, 1, 0.40])\n",
    "librosa.display.specshow(X, ax=ax_X, x_axis='frames', y_axis='chroma', cmap='gray_r', hop_length=H)\n",
    "ax_X.set_ylabel('Cromagrama de Emily')\n",
    "ax_X.set_xlabel('Tiempo (frames)')\n",
    "ax_X.xaxis.tick_top()\n",
    "ax_X.xaxis.set_label_position('top') \n",
    "# ax_X.set_title('Emily')\n",
    "\n",
    "ax_Y = plt.axes([0, 0, 1, 0.40])\n",
    "librosa.display.specshow(Y, ax=ax_Y, x_axis='frames', y_axis='chroma', cmap='gray_r', hop_length=H)\n",
    "ax_Y.set_ylabel('Cromagrama de The Police')\n",
    "ax_Y.set_xlabel('Tiempo (frames)')\n",
    "# ax_Y.set_title('The Police')\n",
    "\n",
    "step = 100\n",
    "y_min_X, y_max_X = ax_X.get_ylim()\n",
    "y_min_Y, y_max_Y = ax_Y.get_ylim()\n",
    "for t in P[0:-1:step, :]: \n",
    "    ax_X.vlines(t[0], y_min_X, y_max_X, color='r')\n",
    "    ax_Y.vlines(t[1], y_min_Y, y_max_Y, color='r')\n",
    "\n",
    "ax = plt.axes([0, 0.40, 1, 0.20])\n",
    "for p in P[0:-1:step, :]: \n",
    "    ax.plot((p[0]/N, p[1]/M), (1, -1), color='r')\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of warping path obtained from MrMsDTW:', P.T.shape[1])\n",
    "wp = make_path_strictly_monotonic(P.T)\n",
    "print('Length of warping path made strictly monotonic:', wp.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libtsm\n",
    "\n",
    "pitch_shift_for_audio_1 = -opt_chroma_shift % 12\n",
    "if pitch_shift_for_audio_1 > 6:\n",
    "    pitch_shift_for_audio_1 -= 12\n",
    "audio_1_shifted = libtsm.pitch_shift(X_wav, pitch_shift_for_audio_1 * 100, order=\"tsm-res\")\n",
    "\n",
    "L = 2048\n",
    "R = 256\n",
    "\n",
    "X_stft, X_env, X_exc, _, _ = analysis_STFT_LPC(X_wav, Fs, L, R)\n",
    "Xs_stft, Xs_env, Xs_exc, _, _ = analysis_STFT_LPC(audio_1_shifted[:,0], Fs, L, R)\n",
    "\n",
    "Xm_stft = Xs_exc*X_env\n",
    "\n",
    "xm = synthesis_STFT(Xm_stft, L, R)\n",
    "\n",
    "# The TSM functionality of the libtsm library expects the warping path to be given in audio samples.\n",
    "# Here, we do the conversion and additionally clip values that are too large.\n",
    "time_map = wp.T * H\n",
    "time_map = np.concatenate((time_map, np.array([[len(X_wav)-1,len(Y_wav)-1]])))\n",
    "\n",
    "time_map = libtsm.ensure_validity(time_map)\n",
    "\n",
    "y_hpstsm = libtsm.hps_tsm(X_wav, time_map)\n",
    "stereo_sonification = np.hstack((Y_wav.reshape(-1, 1), y_hpstsm))\n",
    "\n",
    "# print('Original signal 1', flush=True)\n",
    "# ipd.display(ipd.Audio(X_wav, rate=Fs, normalize=True))\n",
    "\n",
    "# print('Original signal 2', flush=True)\n",
    "# ipd.display(ipd.Audio(Y_wav, rate=Fs, normalize=True))\n",
    "\n",
    "print('Synchronized versions', flush=True)\n",
    "ipd.display(ipd.Audio(stereo_sonification.T, rate=Fs, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.wavfile.write(\"results/Emily_Police_synchronized.wav\", Fs, stereo_sonification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hpstsm = libtsm.hps_tsm(audio_1_shifted, time_map)\n",
    "stereo_sonification = np.hstack((Y_wav.reshape(-1, 1), y_hpstsm))\n",
    "\n",
    "# print('Original signal 1', flush=True)\n",
    "# ipd.display(ipd.Audio(X_wav, rate=Fs, normalize=True))\n",
    "\n",
    "# print('Original signal 2', flush=True)\n",
    "# ipd.display(ipd.Audio(Y_wav, rate=Fs, normalize=True))\n",
    "\n",
    "print('Synchronized versions', flush=True)\n",
    "ipd.display(ipd.Audio(stereo_sonification.T, rate=Fs, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hpstsm = libtsm.hps_tsm(xm, time_map)\n",
    "stereo_sonification = np.hstack((Y_wav.reshape(-1, 1), y_hpstsm))\n",
    "\n",
    "# print('Original signal 1', flush=True)\n",
    "# ipd.display(ipd.Audio(X_wav, rate=Fs, normalize=True))\n",
    "\n",
    "# print('Original signal 2', flush=True)\n",
    "# ipd.display(ipd.Audio(Y_wav, rate=Fs, normalize=True))\n",
    "\n",
    "print('Synchronized versions', flush=True)\n",
    "ipd.display(ipd.Audio(stereo_sonification.T, rate=Fs, normalize=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sync",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
