{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Calculo de pitch, chromagrama y DTW"
      ],
      "metadata": {
        "id": "kLC6LDtEaFY4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UL2v49PS86us"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import scipy.fft\n",
        "from scipy.linalg import toeplitz, solve\n",
        "\n",
        "from scipy import io, signal\n",
        "from IPython.display import Audio\n",
        "\n",
        "import os\n",
        "import IPython\n",
        "os.environ['NUMBA_CACHE_DIR'] = IPython.paths.get_ipython_cache_dir()\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "fpath = '/content/audiopfinal/data'\n",
        "\n",
        "\n",
        "token = userdata.get('ghToken')\n",
        "!git clone https://{token}@github.com/Cosuki/audiopfinal.git > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "HGawWMxa9We_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yid977tz86ut"
      },
      "outputs": [],
      "source": [
        "def lpc_analysis(s, p=20):\n",
        "    \"\"\" compute the LPC analysis using the autocorrelation method\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : numpy array\n",
        "        windowed signal frame as a numpy 1D array.\n",
        "    p : int\n",
        "        model order.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ak : numpy array\n",
        "         model coefficients.\n",
        "    e : float\n",
        "        minimum mean squared error.\n",
        "    e_norm : float\n",
        "             normalized minimum mean squared error.\n",
        "    \"\"\"\n",
        "    # frame length\n",
        "    N = s.shape[0]\n",
        "\n",
        "    # compute autocorrelation values\n",
        "    r = np.zeros((p+1, 1))\n",
        "    for k in range(p+1):\n",
        "        r[k] = np.dot(s[:N-k].T, s[k:])\n",
        "\n",
        "    # solve to compute model coefficients\n",
        "    ak = solve(toeplitz(r[:p]), r[1:]).squeeze()\n",
        "\n",
        "    # compute mean squared error\n",
        "    e = r[0] - np.dot(ak.T, r[1:])\n",
        "\n",
        "    # compute normalized mean squared error\n",
        "    e_norm = e / r[0]\n",
        "\n",
        "    return ak, e, e_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cio-EmXE86uu"
      },
      "outputs": [],
      "source": [
        "def lpc_decomposition(s_win, ak, e, fs, Ndft, Nw):\n",
        "    # filter obtained from the lpc analysis\n",
        "    S = 1\n",
        "    U = np.concatenate([[1], -ak])\n",
        "\n",
        "    # compute gain\n",
        "    G = np.sqrt(e)\n",
        "\n",
        "    # compute the frequency response of the digital filter\n",
        "    w, H = signal.freqz(G*S, U, worN=Ndft, whole=True)\n",
        "    fw = w / (2 * np.pi) * fs\n",
        "\n",
        "    # impulse response of the LPC filter\n",
        "    delta = np.zeros(Nw)\n",
        "    delta[0] = 1\n",
        "    h = signal.lfilter(G*S, U, delta)\n",
        "\n",
        "    # magnitude spectrum\n",
        "    magH = np.abs(H)\n",
        "    ind_fmx = int(Ndft/2)\n",
        "\n",
        "    # inverse filter\n",
        "    A = S*G\n",
        "    B = U\n",
        "\n",
        "    # compute the excitation from the inverse filter\n",
        "    p = signal.lfilter(B, A, s_win)\n",
        "\n",
        "    # compute the spectrum of the excitation\n",
        "    P = np.fft.fft(p, Ndft)\n",
        "\n",
        "    return H, P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns8Zte-J86uv"
      },
      "outputs": [],
      "source": [
        "def analysis_STFT_LPC(x, fs, L=2048, R=256, win='hann'):\n",
        "    \"\"\" compute the analysis phase of the phase vocoder, i.e. the STFT of the input audio signal\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : numpy array\n",
        "        input audio signal (mono) as a numpy 1D array.\n",
        "    L : int\n",
        "        window length in samples.\n",
        "    R : int\n",
        "        hop size in samples.\n",
        "    win : string\n",
        "          window type as defined in scipy.signal.windows.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X_stft : numpy array\n",
        "             STFT of x as a numpy 2D array.\n",
        "    omega_stft : numpy array\n",
        "                 frequency values in radians.\n",
        "    samps_stft : numpy array\n",
        "                 time sample at the begining of each frame.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # length of the input signal\n",
        "    M = x.size;\n",
        "\n",
        "    # number of points to compute the DFT (FFT)\n",
        "    N = L\n",
        "\n",
        "    # analysis window\n",
        "    window = signal.windows.get_window(win, L)\n",
        "\n",
        "    # total number of analysis frames\n",
        "    num_frames = int(np.floor((M - L) / R))\n",
        "\n",
        "    # initialize stft\n",
        "    X_stft = np.zeros((N, num_frames), dtype = complex)\n",
        "    X_env = np.zeros((N, num_frames), dtype = complex)\n",
        "    X_exc = np.zeros((N, num_frames), dtype = complex)\n",
        "\n",
        "    # process each frame\n",
        "    for ind in range(num_frames):\n",
        "\n",
        "        # initial and ending points of the frame\n",
        "        n_ini = int(ind * R)\n",
        "        n_end = n_ini + L\n",
        "\n",
        "        # signal frame\n",
        "        xr = window*x[n_ini:n_end]\n",
        "\n",
        "        # save DFT of the signal frame\n",
        "        X_stft[:, ind] = scipy.fft.fft(xr, N)\n",
        "\n",
        "        # LPC\n",
        "        if np.max(abs(xr))>1e-8:\n",
        "            ak, e, _ = lpc_analysis(xr, p=20)\n",
        "            X_env[:, ind], X_exc[:, ind] = lpc_decomposition(xr, ak, e, fs, N, N)\n",
        "\n",
        "    # frequency values in radians\n",
        "    omega_stft = 2*np.pi*np.arange(N)/N\n",
        "\n",
        "    # time sample at the center of each frame\n",
        "    samps_stft = np.arange(L/2, M-L/2, R)[:-1]\n",
        "\n",
        "    return X_stft, X_env, X_exc, omega_stft, samps_stft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HYmhEhU86uv"
      },
      "outputs": [],
      "source": [
        "def synthesis_STFT(X_stft, L=2048, R=256, win='hann'):\n",
        "    \"\"\" compute the synthesis using the IFFT of each frame combined with overlap-add\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X_stft : numpy array\n",
        "             STFT of x as a numpy 2D array.\n",
        "    L : int\n",
        "        window length in samples.\n",
        "    R : int\n",
        "        hop size in samples.\n",
        "    win : string\n",
        "          window type as defined in scipy.signal.windows.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    x : numpy array\n",
        "        output audio signal (mono) as a numpy 1D array.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # number of frequency bins\n",
        "    N = X_stft.shape[0];\n",
        "\n",
        "    # analysis window\n",
        "    window = signal.windows.get_window(win, L)\n",
        "\n",
        "    # total number of analysis frames\n",
        "    num_frames = X_stft.shape[1]\n",
        "\n",
        "    # initialize otuput signal in the time domain\n",
        "    y = np.zeros(num_frames * R + L)\n",
        "\n",
        "    # process each frame\n",
        "    for ind in range(num_frames):\n",
        "\n",
        "        # reconstructed signal frame\n",
        "        yr = scipy.fft.ifft(X_stft[:,ind], L).real\n",
        "\n",
        "        # initial and ending points of the frame\n",
        "        n_ini = ind*R\n",
        "        n_end = ind*R + L\n",
        "\n",
        "        # overlap-add the signal frame\n",
        "        y[n_ini:n_end] += window*yr\n",
        "\n",
        "    # compute the amplitude scaling factor\n",
        "    C = (L/2)/R\n",
        "\n",
        "    # compensate the amplitude scaling factor\n",
        "    y /= C\n",
        "\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gseb0CD_86uv"
      },
      "outputs": [],
      "source": [
        "dir_files = './data/'\n",
        "\n",
        "X_wav, Fs = librosa.load(f'{fpath}/Emily_Linge-vocals.wav')\n",
        "Y_wav, Fs = librosa.load(f'{fpath}/Police-vocals-guitar.wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estimacion de pitch"
      ],
      "metadata": {
        "id": "QGLViww-YU6t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSOsZQrw86uw"
      },
      "outputs": [],
      "source": [
        "tuning_offset_1 = librosa.estimate_tuning(y=X_wav, sr=Fs)\n",
        "tuning_offset_2 = librosa.estimate_tuning(y=Y_wav, sr=Fs)\n",
        "print('Estimated tuning deviation for recording 1: %f cents, for recording 2: %f cents' % (tuning_offset_1, tuning_offset_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculo Chromagramas"
      ],
      "metadata": {
        "id": "mEfCYGYUYP8p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFwxkUKZ86uw"
      },
      "outputs": [],
      "source": [
        "N = 2048\n",
        "H = 4096\n",
        "X = librosa.feature.chroma_stft(y=X_wav, sr=Fs, norm=2, hop_length=H, n_fft=N, tuning=tuning_offset_1)\n",
        "X = X / X.max()\n",
        "Y = librosa.feature.chroma_stft(y=Y_wav, sr=Fs, norm=2, hop_length=H, n_fft=N, tuning=tuning_offset_2)\n",
        "Y = Y / Y.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzrhB4-c86uw"
      },
      "outputs": [],
      "source": [
        "!pip install pandas > /dev/null 2>&1 # Actualizo pandas\n",
        "!pip install synctoolbox  > /dev/null 2>&1 # Instalo synctoolbox\n",
        "from synctoolbox.dtw.utils import compute_optimal_chroma_shift, shift_chroma_vectors, make_path_strictly_monotonic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDpYSr2J86uw"
      },
      "outputs": [],
      "source": [
        "opt_chroma_shift = compute_optimal_chroma_shift(X, Y)\n",
        "print('Pitch shift between recording 1 and recording 2, determined by DTW:', opt_chroma_shift, 'bins')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-uR2_xy86uw"
      },
      "outputs": [],
      "source": [
        "N = 2048\n",
        "H = int(0.02*Fs)\n",
        "X = librosa.feature.chroma_stft(y=X_wav, sr=Fs, norm=2, hop_length=H, n_fft=N, tuning=tuning_offset_1)\n",
        "X = X / X.max()\n",
        "Y = librosa.feature.chroma_stft(y=Y_wav, sr=Fs, norm=2, hop_length=H, n_fft=N, tuning=tuning_offset_2)\n",
        "Y = Y / Y.max()\n",
        "\n",
        "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(13,5))\n",
        "\n",
        "img = librosa.display.specshow(X, x_axis='frames', y_axis='chroma', cmap='gray_r', hop_length=H, ax=axs[0])\n",
        "axs[0].set_title('Chromagrama de Emily ($hop=20ms$)')\n",
        "axs[0].set_xlabel('Tiempo (frames)')\n",
        "axs[0].set_ylabel('Notas')\n",
        "img.set_clim(0, 1)\n",
        "fig.colorbar(img, ax=axs[0])\n",
        "fig.tight_layout()\n",
        "\n",
        "img = librosa.display.specshow(Y, x_axis='frames', y_axis='chroma', cmap='gray_r', hop_length=H, ax=axs[1])\n",
        "axs[1].set_title('Chromagrama de The Police ($hop=20ms$)')\n",
        "axs[1].set_xlabel('Tiempo (frames)')\n",
        "axs[1].set_ylabel('Notas')\n",
        "img.set_clim(0, 1)\n",
        "fig.colorbar(img, ax=axs[1])\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfcUa12Q86ux"
      },
      "outputs": [],
      "source": [
        "Y = shift_chroma_vectors(Y, opt_chroma_shift)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7E9rUB486ux"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(13,5))\n",
        "\n",
        "img = librosa.display.specshow(X, x_axis='frames', y_axis='chroma', cmap='gray_r', hop_length=H, ax=axs[0])\n",
        "axs[0].set_title('Chromagrama de Emily ($hop=20ms$)')\n",
        "axs[0].set_xlabel('Tiempo (frames)')\n",
        "axs[0].set_ylabel('Notas')\n",
        "img.set_clim(0, 1)\n",
        "fig.colorbar(img, ax=axs[0])\n",
        "fig.tight_layout()\n",
        "\n",
        "img = librosa.display.specshow(Y, x_axis='frames', y_axis='chroma', cmap='gray_r', hop_length=H, ax=axs[1])\n",
        "axs[1].set_title('Chromagrama de The Police shifteado ($hop=20ms$)')\n",
        "axs[1].set_xlabel('Tiempo (frames)')\n",
        "axs[1].set_ylabel('Notas')\n",
        "img.set_clim(0, 1)\n",
        "fig.colorbar(img, ax=axs[1])\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementacion de DTW a chromagramas"
      ],
      "metadata": {
        "id": "dlnUtNSpYbM_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La5xwa5886ux"
      },
      "outputs": [],
      "source": [
        "import libfmp.c3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxmG9xeP86ux"
      },
      "outputs": [],
      "source": [
        "C = libfmp.c3.compute_cost_matrix(X, Y)\n",
        "D = libfmp.c3.compute_accumulated_cost_matrix(C)\n",
        "P = libfmp.c3.compute_optimal_warping_path(D)\n",
        "\n",
        "plt.close('all')\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "ax = plt.subplot(1, 2, 1)\n",
        "libfmp.c3.plot_matrix_with_points(C, P, linestyle='-',  marker='',\n",
        "    ax=[ax], aspect='equal', clim=[0, np.max(C)],\n",
        "    title='Matriz de costo', xlabel='Chroma Emily', ylabel='Chroma Sting');\n",
        "\n",
        "ax = plt.subplot(1, 2, 2)\n",
        "libfmp.c3.plot_matrix_with_points(D, P, linestyle='-', marker='',\n",
        "    ax=[ax], aspect='equal', clim=[0, np.max(D)],\n",
        "    title='Matriz de costo acumulado', xlabel='Chroma Emily', ylabel='Chroma Sting');\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYWBYr4q86uy"
      },
      "outputs": [],
      "source": [
        "N = X.shape[1]\n",
        "M = Y.shape[1]\n",
        "\n",
        "plt.figure(figsize=(13, 5))\n",
        "ax_X = plt.axes([0, 0.60, 1, 0.40])\n",
        "librosa.display.specshow(X, ax=ax_X, x_axis='frames', y_axis='chroma', cmap='gray_r', hop_length=H)\n",
        "ax_X.set_ylabel('Cromagrama de Emily')\n",
        "ax_X.xaxis.tick_top()\n",
        "\n",
        "plt.title('Correspondencia temporal de chromagramas')\n",
        "ax_Y = plt.axes([0, 0, 1, 0.40])\n",
        "librosa.display.specshow(Y, ax=ax_Y, x_axis='frames', y_axis='chroma', cmap='gray_r', hop_length=H)\n",
        "ax_Y.set_ylabel('Cromagrama de The Police')\n",
        "ax_Y.set_xlabel('Tiempo (frames)')\n",
        "\n",
        "step = 100\n",
        "y_min_X, y_max_X = ax_X.get_ylim()\n",
        "y_min_Y, y_max_Y = ax_Y.get_ylim()\n",
        "for t in P[0:-1:step, :]:\n",
        "    ax_X.vlines(t[0], y_min_X, y_max_X, color='r')\n",
        "    ax_Y.vlines(t[1], y_min_Y, y_max_Y, color='r')\n",
        "\n",
        "ax = plt.axes([0, 0.40, 1, 0.20])\n",
        "for p in P[0:-1:step, :]:\n",
        "    ax.plot((p[0]/N, p[1]/M), (1, -1), color='r')\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(-1, 1)\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpqK2NOv86uy"
      },
      "outputs": [],
      "source": [
        "# Convierto el path en creciente estricto, necesario para algoritmo posterior\n",
        "\n",
        "print('Length of warping path obtained from MrMsDTW:', P.T.shape[1])\n",
        "wp = make_path_strictly_monotonic(P.T)\n",
        "print('Length of warping path made strictly monotonic:', wp.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sintetizacion pistas sincronizadas"
      ],
      "metadata": {
        "id": "Qa1PEVErYmbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install libtsm > /dev/null 2>&1\n",
        "import libtsm"
      ],
      "metadata": {
        "id": "2la_G4_5Iv4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSXeGnlr86uy"
      },
      "outputs": [],
      "source": [
        "pitch_shift_for_audio_1 = -opt_chroma_shift % 12\n",
        "if pitch_shift_for_audio_1 > 6:\n",
        "    pitch_shift_for_audio_1 -= 12\n",
        "audio_1_shifted = libtsm.pitch_shift(X_wav, pitch_shift_for_audio_1 * 100, order=\"tsm-res\")\n",
        "\n",
        "L = 2048\n",
        "R = 256\n",
        "\n",
        "X_stft, X_env, X_exc, _, _ = analysis_STFT_LPC(X_wav, Fs, L, R)\n",
        "Xs_stft, Xs_env, Xs_exc, _, _ = analysis_STFT_LPC(audio_1_shifted[:,0], Fs, L, R)\n",
        "\n",
        "Xm_stft = Xs_exc*X_env\n",
        "\n",
        "xm = synthesis_STFT(Xm_stft, L, R)\n",
        "\n",
        "# The TSM functionality of the libtsm library expects the warping path to be given in audio samples.\n",
        "# Here, we do the conversion and additionally clip values that are too large.\n",
        "time_map = wp.T * H\n",
        "time_map = np.concatenate((time_map, np.array([[len(X_wav)-1,len(Y_wav)-1]])))\n",
        "\n",
        "time_map = libtsm.ensure_validity(time_map)\n",
        "\n",
        "y_hpstsm = libtsm.hps_tsm(X_wav, time_map)\n",
        "stereo_sonification = np.hstack((Y_wav.reshape(-1, 1), y_hpstsm))\n",
        "\n",
        "ipd.display(ipd.Audio(stereo_sonification.T, rate=Fs, normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Versiones original y cover shifteado sincronizadas"
      ],
      "metadata": {
        "id": "nAQQdgdwYuMr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7rWsjPX86uy"
      },
      "outputs": [],
      "source": [
        "y_hpstsm = libtsm.hps_tsm(audio_1_shifted, time_map)\n",
        "stereo_sonification = np.hstack((Y_wav.reshape(-1, 1), y_hpstsm))\n",
        "\n",
        "ipd.display(ipd.Audio(stereo_sonification.T, rate=Fs, normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Versiones original y cover shifteado mas timbre corregido sincronizadas"
      ],
      "metadata": {
        "id": "zED0I0JoY0xK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Rknka0i86uy"
      },
      "outputs": [],
      "source": [
        "y_hpstsm = libtsm.hps_tsm(xm, time_map)\n",
        "stereo_sonification = np.hstack((Y_wav.reshape(-1, 1), y_hpstsm))\n",
        "\n",
        "ipd.display(ipd.Audio(stereo_sonification.T, rate=Fs, normalize=True))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sync",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}